{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjFmmAEGS7E1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.applications.vgg19 import VGG19 # importing the model.\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.python.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.python.keras.models import Model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "colab_type": "code",
    "id": "t1xIw7lcS7E4",
    "outputId": "cbe97338-e930-4839-c3b7-c3a1403409ff"
   },
   "outputs": [],
   "source": [
    "model = VGG19(include_top = False,weights = 'imagenet')# we don't need the top layer and the weights of imagenet are assigned\n",
    "model.trainable = False # We only want to apply the pre_trained weights to our inputs instead of training the model with the inputs.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vJojbKNS7FC"
   },
   "outputs": [],
   "source": [
    "def load_and_process_image(image_path):\n",
    "  img=load_img(image_path)\n",
    "  img=img_to_array(img)\n",
    "  img=preprocess_input(img)\n",
    "  img=np.expand_dims(img, axis = 0) # because the model expects as 4-dim input\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Dlz472kS7FE"
   },
   "outputs": [],
   "source": [
    "def deprocess(x):\n",
    "  # perform the inverse of the preprocessiing step\n",
    "  x[:,:,0] += 103.939\n",
    "  x[:,:,1] += 116.779\n",
    "  x[:,:,2] += 123.68\n",
    "  x = x[:,:,::-1] # reversing the order of channels.\n",
    "  x = np.clip(x, 0, 255).astype('uint8') # 0-255 is the range of pixels values\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6lh4Q6K5mLP"
   },
   "outputs": [],
   "source": [
    "def display_image(image,save=False):\n",
    "  if len(image.shape) == 4:\n",
    "      img = np.squeeze(image, axis = 0) # reducing 4-dim to 3-dim\n",
    "  img = deprocess(img)\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(img)\n",
    "  if save==True:\n",
    "    plt.savefig('Output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkgmgrrlS7FK"
   },
   "outputs": [],
   "source": [
    "def load_and_save_img(path,con=True):\n",
    "  img=cv2.imread(path)\n",
    "  res=cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "  if(con):\n",
    "    cv2.imwrite('ContentImg.jpg',res)\n",
    "  else:\n",
    "    cv2.imwrite('StyleImg.jpg',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfCOKVyLS7FN"
   },
   "outputs": [],
   "source": [
    "style_layers = ['block1_conv1','block1_conv2','block2_conv1','block2_conv2','block3_conv1'] # layers from which features of style img are extracted \n",
    "content_layer = 'block4_conv4'# layers from which features of content img are extracted\n",
    "# intermediate models\n",
    "content_model = Model(inputs = model.input,outputs = model.get_layer(content_layer).output)\n",
    "style_models = [Model(inputs = model.input,outputs = model.get_layer(layer).output) for layer in style_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joIHQxxPS7FP"
   },
   "outputs": [],
   "source": [
    "# Content Cost\n",
    "def content_cost(content, generated):\n",
    "  a_C = content_model(content)\n",
    "  a_G = content_model(generated)\n",
    "  cost = tf.reduce_mean(tf.square(a_C - a_G))\n",
    "  return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCGDHH5sS7FV"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(A):\n",
    "  channels = int(A.shape[-1])\n",
    "  a = tf.reshape(A, [-1, channels]) # shape from x,y,c to x*y,c\n",
    "  n = tf.shape(a)[0]\n",
    "  gram = tf.matmul(a, a, transpose_a = True) #a.aT\n",
    "  return gram / tf.cast(n, tf.float32)# scaling down using no of elements n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrF39dDrS7Fa"
   },
   "outputs": [],
   "source": [
    "style_layer_wts = [1.0, 0.8, 0.1, 0.1, 0.2]\n",
    "def style_cost(style, generated):\n",
    "  J_style = 0    \n",
    "  for i,style_model in enumerate(style_models):\n",
    "    a_S = style_model(style)\n",
    "    a_G = style_model(generated)\n",
    "    GS = gram_matrix(a_S)\n",
    "    GG = gram_matrix(a_G)\n",
    "    current_cost = tf.reduce_mean(tf.square(GS - GG))*style_layer_wts[i]\n",
    "    J_style += current_cost \n",
    "  return (J_style/(224*224*len(style_models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mj48u8udS7Fd"
   },
   "outputs": [],
   "source": [
    "generated_images = []\n",
    "costs=[]\n",
    "def training_loop(content_path, style_path, iterations = 10, a = 30., b = 10.):\n",
    "  # initialise\n",
    "  content = load_and_process_image(content_path)\n",
    "  style = load_and_process_image(style_path)\n",
    "  generated = tf.Variable(content, dtype = tf.float32)    \n",
    "  opt = tf.optimizers.Adam(learning_rate = 10.) \n",
    "  for i in range(iterations):\n",
    "    with tf.GradientTape() as tape:\n",
    "      J_content = content_cost(content, generated)\n",
    "      J_style = style_cost(style, generated)\n",
    "      J_total = a * J_content + b * J_style\n",
    "    grads = tape.gradient(J_total, generated)\n",
    "    opt.apply_gradients([(grads, generated)])\n",
    "    costs.append(J_total.numpy())\n",
    "    if i%50==0:\n",
    "      display_image(generated.numpy())\n",
    "      generated_images.append(generated.numpy())\n",
    "      print(\"Iteration:{}, Total Cost:{}\".format(i+1,J_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "uuMit9wjvxO-",
    "outputId": "7149e1b9-0ce8-46db-fdf7-098b205aa0bc"
   },
   "outputs": [],
   "source": [
    "load_and_save_img('content.jpg',True)\n",
    "load_and_save_img('style.jpg',False)\n",
    "img = load_and_process_image('ContentImg.jpg')\n",
    "display_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "DVVskySYS7Ff",
    "outputId": "5d679e0c-0814-4cb9-ecc3-8e4a8b63e031"
   },
   "outputs": [],
   "source": [
    "iterations=200\n",
    "training_loop('ContentImg.jpg','StyleImg.jpg',iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "_qaLQqqlPEHu",
    "outputId": "864488ae-2844-4d1a-9a4b-269b1fa4afaa"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(iterations), costs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Total Cost\")\n",
    "plt.show()\n",
    "display_image(generated_images[-1],True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
